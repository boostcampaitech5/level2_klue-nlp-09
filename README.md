# ë¬¸ì¥ ë‚´ ê°œì²´ê°„ ê´€ê³„ ì¶”ì¶œ

![asdf](https://user-images.githubusercontent.com/82187742/236622385-1af75b87-b5ef-4028-9b82-a52981007cf7.png)

---

# 1. ê°œìš”

### ëŒ€íšŒ Task: **ë¬¸ì¥ ë‚´ ê°œì²´ê°„ ê´€ê³„ ì¶”ì¶œ**

ê´€ê³„ ì¶”ì¶œ(Relation Extraction)ì€ ë¬¸ì¥ì˜ ë‹¨ì–´(Entity)ì— ëŒ€í•œ ì†ì„±ê³¼ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ê´€ê³„ ì¶”ì¶œì€ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•ì„ ìœ„í•œ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¡œ, êµ¬ì¡°í™”ëœ ê²€ìƒ‰, ê°ì • ë¶„ì„, ì§ˆë¬¸ ë‹µë³€í•˜ê¸°, ìš”ì•½ê³¼ ê°™ì€ ìì—°ì–´ì²˜ë¦¬ ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ ì¤‘ìš”í•©ë‹ˆë‹¤. ë¹„êµ¬ì¡°ì ì¸ ìì—°ì–´ ë¬¸ì¥ì—ì„œ êµ¬ì¡°ì ì¸ tripleì„ ì¶”ì¶œí•´ ì •ë³´ë¥¼ ìš”ì•½í•˜ê³ , ì¤‘ìš”í•œ ì„±ë¶„ì„ í•µì‹¬ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ë²ˆ ëŒ€íšŒì—ì„œëŠ” ë¬¸ì¥, ë‹¨ì–´ì— ëŒ€í•œ ì •ë³´ë¥¼ í†µí•´ ,ë¬¸ì¥ ì†ì—ì„œ ë‹¨ì–´ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì¶”ë¡ í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìš°ë¦¬ì˜ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ ë‹¨ì–´ë“¤ì˜ ì†ì„±ê³¼ ê´€ê³„ë¥¼ íŒŒì•…í•˜ë©° ê°œë…ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ëª¨ë¸ì´ ì •ë§ ì–¸ì–´ë¥¼ ì˜ ì´í•´í•˜ê³  ìˆëŠ” ì§€, í‰ê°€í•´ ë³´ë„ë¡ í•©ë‹ˆë‹¤.

### í™œìš© ì¥ë¹„ ë° ì¬ë£Œ

- **ì„œë²„**: AI Stage (NVIDIA V100 32GB)
- **IDE**: VSCode, Jupyter Lab

- **í˜‘ì—…**: Git(GitHub), Notion, Slack
- **ëª¨ë‹ˆí„°ë§**: WandB

---

# 2. íŒ€ êµ¬ì„± ë° ì—­í• 

### ê¹€ì„¸í˜•\_T5038

- ë°ì´í„° EDA ë° preprocessing(easy data aug.)
- Hyperparameter tuning: kogpt2, twhin-bert-large, xlm-roberta-large
- Model evaluation(ì¶œë ¥ ê²°ê³¼ ë¶„ì„ ë“±)

### ì´ì¤€ì„ \_T5157

- pytorch lightning base code ì‘ì„±
- ë°ì´í„° EDA
- Hyperparameter tuning: klue/bert-base, klue/roberta-large

### í™ì°¬ìš°\_T5227

- ë°ì´í„° EDA (ë‹¨ì–´ ë¹ˆë„ ë¶„ì„, [UNK] í† í° í™•ì¸)
- ëª¨ë¸ íƒìƒ‰ ë° ì„±ëŠ¥ ë¹„êµ
- Hyperparameter tuning : mluke, kobart

### ì´ë™í˜¸\_T5139

- ë°ì´í„° EDA
- Hyperparameter tuning: google/rembert, klue/bert-base
- ë°ì´í„° preprocessing(Entity Representation)

### ì •ìœ¤ì„\_T5194

- ë°ì´í„° Preprocessing ì—°ê²° íŒŒì¼
- Clean Foreign Language í•¨ìˆ˜ ì‘ì„±
- snunlp/kr-electra-discriminator Modeling
- ë°ì´í„° EDA

---

# 3. ìˆ˜í–‰ ì ˆì°¨ ë° ë°©ë²•

## 3.0. Base Code ì‘ì„±(ì´ì¤€ì„ )

- **pytorch lightning ê¸°ë°˜ base code ì‘ì„±**
  - ì‹¤í—˜ì˜ í¸ì˜ì„± í–¥ìƒ(logging, sweep ë“±)
  - Dataloader ì»¤ìŠ¤í…€ ìš©ì´(í† í° ì¶”ê°€, ì „ì²˜ë¦¬ ë“±)

## 3.1. EDA

### 3.1.1. Data Distribution (ê¹€ì„¸í˜•)

- ê¸°ë³¸ì ìœ¼ë¡œ ë°ì´í„°ëŠ” `id`, `sentence`, `subject_entity`, `object_entity`, `label`, `source`ë¡œ êµ¬ì„±
- `train` ë°ì´í„°ì˜ ê²½ìš° 32,470ê°œ, `test` ë°ì´í„°ì˜ ê²½ìš° 7,765ê°œê°€ ì¡´ì¬
- í¬ê²Œ `no_relation`, `per`(person), `org`(organization)ì˜ ì„¸ main-label, ê·¸ ì•„ë˜ë¡œ `per` ì´í•˜ 17ê°œ, `org` ì´í•˜ 12ê°œì˜ sub-labelì´ ì¡´ì¬í•˜ì—¬ ì´ 30ê°œì˜ classë¡œ ë¶„ë¥˜

**Sub-label ë³„ data distribution [ê·¸ë¦¼ 3.1]**

![ê·¸ë¦¼ 3.1. Sub-label ë³„ data distribution](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/1.png)

ê·¸ë¦¼ 3.1. Sub-label ë³„ data distribution

- ê°€ì¥ ê¸°ë³¸ì ìœ¼ë¡œ 30ê°œì˜ sub-label ë³„ë¡œ ëª‡ ê°œì˜ ë°ì´í„°ê°€ ë¶„í¬í•˜ëŠ”ì§€ í™•ì¸
- `no_relation` ë°ì´í„°ëŠ” 32,470ê°œ ì¤‘ 9,534ê°œ(ì•½ 29.36%)ë¥¼ ì°¨ì§€í•˜ë©° ê°€ì¥ ë§ì€ ë¹„ìœ¨ì„ ë³´ì˜€ìœ¼ë©°, ì´ë¥¼ ì œì™¸í•œ ë°ì´í„° ì¤‘ ê°€ì¥ ë§ì€ ë°ì´í„°ëŠ” `org:top_member/employee`(4,284ê°œ, 13.19%), ê°€ì¥ ì ì€ ë°ì´í„°ëŠ” `per:place_of_death`(40ê°œ, 0.12%)ë¡œ í™•ì¸ë˜ì–´, imbalanceê°€ ë§¤ìš° í° ê²ƒìœ¼ë¡œ ì¡°ì‚¬ë˜ì—ˆìŒ

**Main-label ë³„ data distribution [ê·¸ë¦¼ 3.2]**

![ê·¸ë¦¼ 3.2. Main-label ë³„ data distribution](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/2.png)

ê·¸ë¦¼ 3.2. Main-label ë³„ data distribution

- Sub-label ë³„ distribution í™•ì¸ ê²°ê³¼ main-label ë³„ ë°ì´í„° ë¹„ìœ¨ì€ sub-label ë§Œí¼ ìƒì´í•˜ì§€ ì•Šì„ ê²ƒì´ë¼ íŒë‹¨í•˜ì˜€ê³ , ì¶”í›„ main-label ë¶„ë¥˜ â†’ sub-label ë¶„ë¥˜ í˜•íƒœì˜ ëª¨ë¸ ì œì‘ì˜ ê°€ëŠ¥ì„±ì„ ì¡°ì‚¬í•˜ê¸° ìœ„í•´ 3ê°œì˜ main-label ë³„ ë¶„í¬ í™•ì¸
- `no_relation`(NR)ê³¼ `per` ë°ì´í„°ëŠ” ê° 9,534ê°œ(29.36%), 9,081ê°œ(27.97%)ë¡œ ìœ ì‚¬í•˜ë©°, org ë°ì´í„°ê°€ 13,855ê°œ(42.67%)ë¡œ ê°€ì¥ ë§ìŒì„ í™•ì¸
- Main-label ë‚´ sub-label ë°ì´í„° ë¶„í¬ í™•ì¸ [ê·¸ë¦¼ 3.3, 3.4]
  ![ê·¸ë¦¼ 3.3. `org` label ë‚´ data distribution](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/3.png)
  ê·¸ë¦¼ 3.3. `org` label ë‚´ data distribution
  ![ê·¸ë¦¼ 3.4. `per` label ë‚´ data distribution](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/4.png)
  ê·¸ë¦¼ 3.4. `per` label ë‚´ data distribution
  - ë‹¤ë§Œ, sub-labelì´ ì—†ì–´ ê°€ì¥ ë§ì€ sub-label ë¹„ìœ¨ì„ ì°¨ì§€í•œ no_relation ë°ì´í„°ë¥¼ ì œì™¸í•˜ë”ë¼ë„, org ë°ì´í„°ì™€ per ë°ì´í„°ì˜ imbalanceëŠ” ë†’ìœ¼ë¯€ë¡œ ë¶„ë¥˜ ê³¼ì •ì„ ë¶„í• í•œë‹¤ í•˜ë”ë¼ë„ ì—¬ì „íˆ handlingì´ í•„ìš”í•  ê²ƒìœ¼ë¡œ í™•ì¸ë˜ì—ˆìŒ

**Source ë³„ data distribution**

- ì „ì²´ ë°ì´í„°ëŠ” `wikipedia`, `wikitree`, `policy-briefing`ì˜ ì„¸ ê°œ sourceë¡œë¶€í„° í™•ë³´ë˜ì—ˆìœ¼ë©°, í•´ë‹¹ ë°ì´í„°ì˜ ì¶”í›„ ëª¨ë¸ í•™ìŠµì— ëŒ€í•œ í™œìš© ê°€ëŠ¥ì„± ì¡°ì‚¬ë¥¼ ìœ„í•´ source ë³„ë¡œ ë°ì´í„° ë¶„í¬ë¥¼ í™•ì¸
- train ë°ì´í„°[ê·¸ë¦¼ 3.5]ì˜ ê²½ìš° `wikipedia` ë°ì´í„°ì˜ ë¹„ìœ¨ì´ 60% ì´ìƒìœ¼ë¡œ ë†’ê³ , `policy-briefing` ë°ì´í„°ì˜ ê²½ìš° 1% ë¯¸ë§Œì˜ ê·¹ì†Œìˆ˜ë¥¼ ì°¨ì§€í•˜ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸
  ![ê·¸ë¦¼ 3.5. Train ë°ì´í„°ì˜ source ë¶„í¬](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/5.png)
  ê·¸ë¦¼ 3.5. Train ë°ì´í„°ì˜ source ë¶„í¬
  - train ë°ì´í„°ì˜ source ì¤‘ ê·¹ì†Œìˆ˜ì¸ `policy-briefing`ì„ ì œì™¸í•œ `wikipedia`, `wikitree`ì˜ ë°ì´í„° sub-label ë¶„í¬ í™•ì¸
    ![ê·¸ë¦¼ 3.6. Wikipedia source ë°ì´í„° ë‚´ sub-label ë¶„í¬](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/6.png)
    ê·¸ë¦¼ 3.6. Wikipedia source ë°ì´í„° ë‚´ sub-label ë¶„í¬
    ![ê·¸ë¦¼ 3.7. Wikitree source ë°ì´í„° ë‚´ sub-label ë¶„í¬](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/7.png)
    ê·¸ë¦¼ 3.7. Wikitree source ë°ì´í„° ë‚´ sub-label ë¶„í¬
    - ë¶„ì„ ê²°ê³¼, `wikipedia` ë°ì´í„°ì— ì „ì²´ 9,534ê°œ `no_relation` ë°ì´í„° ì¤‘ 7,382ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•¨ì„ í™•ì¸í•˜ì˜€ê³ , `wikitree`ì˜ ê²½ìš° `org:top_member/employee` ë°ì´í„° ëŒ€ë‹¤ìˆ˜ê°€ í•´ë‹¹ ì†ŒìŠ¤ì—ì„œ ì¶œì²˜í•œ ëª¨ìŠµì„ í™•ì¸
    - ê²°ë¡ ì ìœ¼ë¡œ, source ë³„ë¡œ ë°ì´í„° ë¶„í¬ì˜ ì°¨ì´ê°€ ëª…í™•íˆ ì¡´ì¬í•¨ì„ ë³´ì•˜ìŒ
- í—ˆë‚˜ test ë°ì´í„°[ê·¸ë¦¼ 3.8]ì˜ ê²½ìš°ì— `wikitree` ë¹„ìœ¨ì´ ê³¼ë°˜ ì´ìƒ ë†’ì€ ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆì–´, test ë°ì´í„°ì˜ sub-label ë¶„í¬ê°€ train ë°ì´í„°ì™€ëŠ” ë‹¤ë¥¼ ìˆ˜ë„ ìˆë‹¤ëŠ” ê°€ëŠ¥ì„±ì„ í™•ì¸
  ![ê·¸ë¦¼ 3.8. Test ë°ì´í„°ì˜ source ë¶„í¬](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/8.png)
  ê·¸ë¦¼ 3.8. Test ë°ì´í„°ì˜ source ë¶„í¬

**Token sequence length distribution [ê·¸ë¦¼ 3.9, 3.10]**

![ê·¸ë¦¼ 3.9. train ë°ì´í„° token sequence length(BERT tokenizer)](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/9.png)

ê·¸ë¦¼ 3.9. train ë°ì´í„° token sequence length(BERT tokenizer)

![ê·¸ë¦¼ 3.10. test ë°ì´í„° token sequence length(BERT tokenizer)](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/10.png)

ê·¸ë¦¼ 3.10. test ë°ì´í„° token sequence length(BERT tokenizer)

- ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œ ëª¨ë¸ì¸ `klue/bert-base` ëª¨ë¸ì˜ BERT tokenizerë¥¼ ì´ìš©í•´ í† í°í™”ëœ token sequence lengthë¥¼ í™•ì¸í•œ ê²°ê³¼, train ë°ì´í„°ì™€ test ë°ì´í„°ì˜ ë¶„í¬ì—ëŠ” í° ì°¨ì´ê°€ ì—†ìŒì„ í™•ì¸

### 3.1.2. `[UNK]` Tokens (ì •ìœ¤ì„)

**unk í† í°ìœ¼ë¡œ ë°”ë€ŒëŠ” ë‹¨ì–´ë“¤ì„ ì¡°ì‚¬**

```python
{"'": 337, 'æ': 225, 'å´”': 60, 'çš‡': 54, 'å': 48, 'â€“': 43, '.': 42, 'å°¹': 38, 'æ°¸': 31, 'æ˜Œ': 31,
'æ…¶': 28, 'å®‹': 28, 'è¶™': 25, 'í™‹ìŠ¤í¼': 24, 'èˆˆ': 23, ')': 22, 'ç›§': 22, 'æ‰¿': 22, 'æ¢': 22, 'å­': 21,
 'å¾': 21, 'å§œ': 21, '!': 21, 'æ²ˆ': 20, 'å®¹': 19, 'é™µ': 19, 'ç”³': 18, 'æ”¾': 18, 'æ± ': 18, 'è²': 18,
'æ´ª': 18, 'é¾': 18, 'å¦ƒ': 16, 'ä¿Š': 16, 'æ³°': 16, 'å³': 16, 'é€²': 15, 'æ´™,': 15, 'æ ¡': 15,
'í™‹ì¹´ì´ë„': 15, 'ç‚³': 15, 'åº·': 14, 'æŸ³': 14, 'å”': 14, 'å´‡': 14, 'ì„': 14, 'å°‘': 13, 'åŠ‰': 13,
'æ™¯': 13, 'ä¿Š,': 13, 'åœ˜': 13, 'â˜031': 13, 'è³¢': 13, 'å¿ ': 13, 'æ©': 13, 'å¤': 12, 'å¬ª': 12,
 'æƒ ': 12, 'ç…¥,': 12, 'ç¿': 12, 'ìˆ€': 12, 'éŒ«': 11, 'ç¾…': 11, 'ç†™,': 11, 'è¨±': 11, 'æ¤,': 10,
'æ¨‚': 10, 'å»¶': 10, 'æ˜­': 10, 'æ•¬': 10, 'ç¯„': 10, 'ç†™': 10, 'ì—': 10, 'ë² ë ê°€ë¦¬ì˜¤': 10, 'å“²,': 10,
 'æ¸…': 10, 'æ­': 10, 'æ°¸,': 10, 'å®£': 10, 'å‹³,': 10, 'æº': 10, 'å»º': 10, 'è—¤': 10, 'ì´ë¼': 10,
'ç¹”': 10, 'å¼': 9, 'ç§‹': 9, 'ë¼ëŠ”': 9, 'ë„´ì´ˆí”„ê°€': 9, 'æ‡¿': 9, 'é˜¿': 9, 'å½¦': 9, 'é¡¯': 9, 'æ–—': 9,
'ä¼¯': 9, 'é¬,': 9, 'ë¥¼': 9, 'å¾': 9, 'ì¥˜': 9, 'í˜¸ì—”ì´ë ˆë¥¸ì§€í¬ë§ˆë§ê²': 9, 'å¥': 9, 'ç§‘': 9, ... }
```

- ëŒ€ë¶€ë¶„ì˜ unk í† í°ë“¤ì€ í•œìë¡œ ë°œìƒí–ˆê¸°ì— Data Preprocessing ì—ì„œ í•œì ì œê±° í•¨ìˆ˜ë¥¼ ë§Œë“¤ê¸°ë¡œ ê²°ì •

### 3.1.3. Word Frequency (í™ì°¬ìš°)

- ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë“¤ì„ ìœ ì˜ì–´ë¡œ ëŒ€ì²´í•˜ëŠ” data augmentation ê¸°ë²•ì„ ê³ ë ¤í•´ ë‹¨ì–´ ë¹ˆë„ìˆ˜ ë¶„ì„
- Special token ë° ë”°ì˜´í‘œì™€ ê°™ì€ ê¸°í˜¸ë“¤ì„ ì œì™¸í•œ ë‹¨ì–´ë“¤ì„ `ë‹¨ì–´: ë¹ˆë„ìˆ˜` í˜•íƒœë¡œ ì •ë¦¬
  ```
  {'í•œêµ­': 2676, 'ëŒ€í•œë¯¼êµ­': 2348, 'ëŒ€í‘œ': 1902, 'ì„ ìˆ˜': 1872, 'FC': 1811, 'ë°í˜”': 1735, 'ëŒ€í†µë ¹': 1710,
  'ì´í›„': 1639, 'ê´‘ì£¼': 1571, 'ë¦¬ê·¸': 1556, 'ì§€ë‚œ': 1496, 'ë¯¸êµ­': 1435, 'ì¶•êµ¬': 1434, 'ê²½ê¸°': 1417,
  'ì¼ë³¸': 1403, 'ì˜ì›': 1348, 'ë§': 1346, 'ì„œìš¸': 1325, 'ì§€ì—­': 1245, 'ì†Œì†': 1184, 'êµ­ê°€': 1175,
  'í›„ë³´': 1139, 'ë”ë¶ˆ': 1130, 'ì½”': 1120, 'ì‹œì¦Œ': 1117, 'ê°ë…': 1093, 'êµ­ë¯¼': 1071, 'ë‹¹ì‹œ': 1060, ...}
  ```

## 3.2. Preprocessing

### 3.2.1. Chinese-Characters Cleaning (ì •ìœ¤ì„)

```python
r'([-=+#/\?:^$.@*\"â€»~&%ã†!ã€\\â€˜|\(\)\[\]\<\>`\'â€¦ã€‹ä¸€-é¿•ã€-ä¶µï¤€-ï«™\sÂ·])'
```

- ìœ„ì˜ ì •ê·œì‹ì„ ì´ìš©í•˜ì—¬ í•œìë¥¼ ê°ì§€í•  ì‹œ í•œìë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜ ìƒì„±
- **ìƒì„± ê²°ê³¼**
  ```python
  Before: ë°•ìš©ì˜¤(æœ´è“‰æ—¿, 1937ë…„ 4ì›” 29ì¼(ìŒë ¥ 3ì›” 19ì¼)(ìŒë ¥ 3ì›” 19ì¼) ~ 2009ë…„ 11ì›” 4ì¼)ëŠ” ì„œìš¸ì—ì„œ íƒœì–´ë‚œ ëŒ€í•œë¯¼êµ­ì˜ ê¸°ì—…ì¸ìœ¼ë¡œ ë‘ì‚°ê·¸ë£¹ íšŒì¥, KBO ì´ì¬ ë“±ì„ ì—­ì„í–ˆë‹¤.
  After: ë°•ìš©ì˜¤(1937ë…„ 4ì›” 29ì¼(ìŒë ¥ 3ì›” 19ì¼)(ìŒë ¥ 3ì›” 19ì¼) ~ 2009ë…„ 11ì›” 4ì¼)ëŠ” ì„œìš¸ì—ì„œ íƒœì–´ë‚œ ëŒ€í•œë¯¼êµ­ì˜ ê¸°ì—…ì¸ìœ¼ë¡œ ë‘ì‚°ê·¸ë£¹ íšŒì¥, KBO ì´ì¬ ë“±ì„ ì—­ì„í–ˆë‹¤.
  ```

### 3.2.2. Data Augmentation (ê¹€ì„¸í˜•)

**Easy data augmentation**

- Wei and Zhou (2019)ì˜ 4ê°€ì§€ easy data augmentation ë°©ë²•ì„ ê°ê°ì˜ í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ì—¬ ì‚¬ìš©í•˜ì˜€ìœ¼ë©°, augmentationìœ¼ë¡œ ì¸í•´ entityì˜ ìœ„ì¹˜ ì •ë³´ê°€ ë³€ë™ëœ ê²½ìš° ë°˜ì˜í•˜ì—¬ ìˆ˜ì • (entity ë‚´ ë‹¨ì–´ëŠ” augmentation ëŒ€ìƒì—ì„œ ì œì™¸)
  - Synonym replacement (SR): ë¬¸ì¥ ë‚´ ì„ì˜ì˜ ë‹¨ì–´ë¥¼ ìœ ì˜ì–´ë¡œ êµì²´ [ê·¸ë¦¼ 3.?]
    ![ê·¸ë¦¼ 3.11. SR augmentation ì˜ˆì‹œ(`ì˜íšŒ` â†’ `ì…ë²•ë¶€`, `ì—°í•©` â†’ `ë™ë§¹`)](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/11.png)
    ê·¸ë¦¼ 3.11. SR augmentation ì˜ˆì‹œ(`ì˜íšŒ` â†’ `ì…ë²•ë¶€`, `ì—°í•©` â†’ `ë™ë§¹`)
  - Random deletion (RD): ë¬¸ì¥ ë‚´ ì„ì˜ì˜ ë‹¨ì–´ë¥¼ ì‚­ì œ [ê·¸ë¦¼ 3.?]
    ![ê·¸ë¦¼ 3.12. RD augmentaion ì˜ˆì‹œ(`ê¹€ë‘ê´€` ì‚­ì œ)](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/12.png)
    ê·¸ë¦¼ 3.12. RD augmentaion ì˜ˆì‹œ(`ê¹€ë‘ê´€` ì‚­ì œ)
  - Random swap (RS): ë¬¸ì¥ ë‚´ ì„ì˜ì˜ ë‹¨ì–´ í•œ ìŒì˜ ìœ„ì¹˜ë¥¼ êµì²´ [ê·¸ë¦¼ 3.?]
    ![ê·¸ë¦¼ 3.?. RS augmentation ì˜ˆì‹œ(`ê¹€ì¢…ì„` - `ì˜ë•` êµì²´)](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/13.png)
    ê·¸ë¦¼ 3.?. RS augmentation ì˜ˆì‹œ(`ê¹€ì¢…ì„` - `ì˜ë•` êµì²´)
  - Random insertion (RI): ë¬¸ì¥ ë‚´ ì„ì˜ì˜ ìœ„ì¹˜ì— ì„ì˜ì˜ ë‹¨ì–´ë¥¼ ì‚½ì… [ê·¸ë¦¼ 3.?]
    ![ê·¸ë¦¼ 3.14. RI augmentation ì˜ˆì‹œ(`í†µë¡œ` ì‚½ì…: `íŒ€ì„ UEFAì»µ` â†’ `íŒ€ì„ í†µë¡œ UEFAì»µ`)](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/14.png)
    ê·¸ë¦¼ 3.14. RI augmentation ì˜ˆì‹œ(`í†µë¡œ` ì‚½ì…: `íŒ€ì„ UEFAì»µ` â†’ `íŒ€ì„ í†µë¡œ UEFAì»µ`)
- SR, RS, RI, RD ìˆœìœ¼ë¡œ ì ìš© ìš°ì„ ìˆœìœ„ë¥¼ ì„¤ì •(ì–¼ë§ˆë‚˜ ë¬¸ì¥ì˜ ì›í˜•ì´ ë³´ì¡´ë˜ëŠ”ì§€ ê¸°ì¤€)í•˜ê³ , ë°ì´í„° ê°œìˆ˜ì— ë”°ë¼ augmentation ê¸°ë²•ì˜ ê°œìˆ˜ë¥¼ ì°¨ë“± ì ìš©
  - (0, 100), [100, 200), [200, 450), [450, 700)ì˜ ë²”ìœ„ì— ê°ê° 4, 3, 2, 1ê°œì˜ ê¸°ë²• ì ìš©

**Entity replacement (ER)**

- Entity ì •ë³´ì— typeì´ ëª…ì‹œë˜ì–´ ìˆëŠ” ì ì— ì°©ì•ˆí•˜ì—¬, entityì˜ ë‹¨ì–´ë¥¼ ë™ì¼í•œ typeì„ ê°€ì§„ ë‹¤ë¥¸ entity ë‹¨ì–´ë¡œ êµì²´
  ![ê·¸ë¦¼ 3.15. ER augmentation ì˜ˆì‹œ(`subject_entity` êµì²´)](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/15.png)
  ê·¸ë¦¼ 3.15. ER augmentation ì˜ˆì‹œ(`subject_entity` êµì²´)
  - Threshold(1,000ê°œ or 2,000ê°œ)ë¥¼ ì„¤ì •í•˜ì—¬, ê°œìˆ˜ê°€ threshold ë¯¸ë§Œì¸ ë°ì´í„°ë¥¼ thresholdê¹Œì§€ augmentation. ë‹¤ë§Œ ìµœëŒ€ ì œí•œì„ augmentation ì´ì „ ë°ì´í„° ê°œìˆ˜ì˜ 2ë°°ë¡œ ë‘ì–´, ER ê¸°ë²•ì´ ê° ë°ì´í„°ì— ìµœëŒ€ 1ë²ˆ ì ìš©ë˜ë„ë¡ ì„¤ì •

**ì „ì²´ augmentation í”„ë¡œì„¸ìŠ¤**

- ìµœëŒ€í•œ ë¶€ì¡±í•œ ë°ì´í„°ë¥¼ ì¦ê°•ì‹œí‚¤ë©´ì„œ, ê³¼ì í•©ì„ í”¼í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ëª©í‘œ
- 6ê°€ì§€ ë²„ì „ì˜ ë°ì´í„°(ëŒ€ì¡°êµ°) ìƒì„± ë° ì‹¤í—˜í•œ ê²°ê³¼, ì£¼ëª©í• ë§Œí•œ ì„±ëŠ¥ í–¥ìƒì€ í™•ì¸ë˜ì§€ ì•Šì•˜ìŒ
  - No aug.
    / easy data aug. only
    / ER(thres: 1,000) only
    / easy data aug. + ER 1,000
    / easy data aug. + ER 2,000
    / easy data aug. + ER 2,000 + no_relation ê°œìˆ˜ ì ˆë°˜ cut

## 3.2.3. Entity Representation (ì´ë™í˜¸)

- **ê°œìš”**
  - ë³¸ ëŒ€íšŒì˜ Trainê³¼ Test datasetì—ëŠ” Entityì˜ typeì´ ì¡´ì¬
    ![ê·¸ë¦¼ 3.16. datasetì˜ entity ì˜ˆì‹œ](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/16.png)
    ê·¸ë¦¼ 3.16. datasetì˜ entity ì˜ˆì‹œ
  - ê¸°ì¡´ base ì½”ë“œì—ì„œëŠ” typeì„ í™œìš©í•˜ì§€ ì•ŠìŒ
  - ì´ë¥¼ í™œìš©í•˜ë©´ ì„±ëŠ¥ í–¥ìƒì„ ì´ë£° ìˆ˜ ìˆì„ ê±°ë¼ íŒë‹¨
- **ë‚´ìš©**

  - Typed Entity Marker([Zhong and Chen, 2021](https://www.notion.so/KLUE-Wrap-Up-Report-7e063543d6154e02ad26f350bcabe04b?pvs=21))ì™€ Typed Entity Marker (punct)([Zhou and Chen, 2021](https://www.notion.so/KLUE-Wrap-Up-Report-7e063543d6154e02ad26f350bcabe04b?pvs=21)), Sentence Swap ì‚¬ìš©
    <aside>
    ğŸ’¡ base

    - [CLS] subj [SEP] obj [SEP] sentence [SEP]

    Sentence Swap

    - baseì— [CLS] obj [SEP] subj [SEP] sentence [SEP] ë°ì´í„° ì¶”ê°€

    Typed Entity Marker

    - sentenceì— <S:TYPE> subj </S:TYPE> â€¦ <O:TYPE> object_entity </O:TYPE> í˜•ì‹ì´ ë˜ëŠ” ë§ˆì»¤ë¥¼ ë¶€ì°©

    Typed Entity Marker (punct)

    - sentenceì— @ _ subj-type _ subj @ ... # âˆ§ obj-type âˆ§ obj # í˜•ì‹ì´ ë˜ëŠ” ë§ˆì»¤ë¥¼ ë¶€ì°©
    </aside>

    - ê°ê°ì˜ markerë¥¼ special tokenìœ¼ë¡œ ë„£ì—ˆì„ ë•Œì™€ ë„£ì§€ ì•Šì•˜ì„ ë•Œ ë¹„êµ

- **ê²°ê³¼**
  ![ê·¸ë¦¼ 3.17 ì‹¤í—˜ ê²°ê³¼](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/17.png)
  ê·¸ë¦¼ 3.17 ì‹¤í—˜ ê²°ê³¼
- **ê²°ë¡ **
  - klue/bert-base ëª¨ë¸ì—ì„œëŠ” Typed Entity Markerê°€ íš¨ê³¼ì 
  - klue/roberta-largeì˜ ê²½ìš° Typed Entity Marker (punct)ê°€ íš¨ê³¼ì 
  - ì´í›„ ëª¨ë¸ í•™ìŠµì€ ë‘ ê°€ì§€ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì ìš©í•˜ì—¬ ì§„í–‰

## 3.3. Model Selection (í™ì°¬ìš°)

<aside>
ğŸ’¡ **ëª¨ë“  ëª¨ë¸ì€ ë™ì¼ ì¡°ê±´ì—ì„œ ì‹¤í—˜í•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•˜ê¸° ìœ„í•´ train, dev dataset ê³ ì • ë° hyperparameter í†µì¼**
`epoch=10`, `learning_rate=1e-5`, `batch_size=16,` `warmup_steps=1000`, `optimizer=AdamW`, `scheduler=StepLR`

</aside>

| ëª¨ë¸                                     | íŒŒë¼ë¯¸í„° ìˆ˜ | F1 / AUPRC (dev) | F1 / AUPRC (public) |
| ---------------------------------------- | ----------- | ---------------- | ------------------- |
| klue/bert-base                           | 125M        | 83.302 / 77.652  |                     |
| klue/roberta-large                       | 355M        | 85.04 / 77.537   |                     |
| xlm-roberta-large                        | 355M        | 84.344 / 78.023  |                     |
| wooy0ng/korquad1-klue-roberta-large      | 355M        | 86.03 / 79.491   | 69,475 / 73.0159    |
| kykim/albert-kor-base                    | 11M         | 79.315 / 65.227  |                     |
| kykim/electra-kor-base                   | 85M         | 77.358 / 49.062  |                     |
| beomi/KcELECTRA-base                     | 85M         | 73.47 / 43.678   |                     |
| snunlp/KR-ELECTRA-discriminator          | 85M         | 79.729 / 63.963  |                     |
| monologg/koelectra-base-v3-discriminator | 85M         | 78.667 / 55.246  |                     |
| skt/kogpt2-base-v2                       | 125M        | 78.174 / 67.998  |                     |
| google/rembert                           | 469M        | 84.84 / 78.663   | 67.5282 / 68.6837   |
| setu4993/LaBSE                           | 470M        | 81.447 / 73.052  |                     |
| timpal01/mdeberta-v3-base-squad2         | 86M         | 79.992 / 61.719  |                     |
| studio-ousia/mluke-large-lite            | 561M        | 85.623 / 79.949  | 69.1844 / 71.59     |
| hfl/cino-large-v2                        | 442M        | 84.624 / 78.901  |                     |

- dev F1 scoreê°€ í˜„ì €íˆ ë‚®ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ëª¨ë¸ì€ ë”°ë¡œ public ì œì¶œ ë° scoreë¥¼ ê³„ì‚°í•˜ì§€ ì•ŠìŒ
- ì‹¤í—˜ ê²°ê³¼, ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ë§ì„ ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„
- ê·¸ ì™¸ fully connected layerì™€ ì—°ê²°í•œ T5, bart modelì„ ì‹œë„í–ˆìœ¼ë‚˜ ì‹¤íŒ¨

**ëª¨ë¸ ì„¤ëª…**

| ëª¨ë¸ | Description |
| ---- | ----------- |

| RoBERTa
-based | Dynamic masking ê¸°ë²•ê³¼ ë” ë§ì€ ë°ì´í„°ë¥¼ í•™ìŠµì— í™œìš©í•˜ì—¬ BERT ëª¨ë¸ì„ ë” ê°•ì¸í•˜ê²Œ ê°œì„ í•œ ëª¨ë¸ |
| ELECTRA
-based | ê¸°ì¡´ BERT ê³„ì—´ì˜ ëª¨ë¸ë“¤ê³¼ ë‹¬ë¦¬ ëŒ€ì²´ í† í° íƒì§€ë¼ëŠ” í›ˆë ¨ ë°©ì‹ì„ í†µí•´ì„œ í›ˆë ¨ |
| ê¸°íƒ€ | RemBERT (Chung et al., 2020)

- ì…ë ¥ ì„ë² ë”©ê³¼ ì¶œë ¥ ì„ë² ë”© ê°„ ê°€ì¤‘ì¹˜ ê³µìœ ë¥¼ í•˜ì§€ ì•ŠìŒ
  MLUKE (Yamada et al.. 2020)
- ë‹¨ì–´ ì‹œí€€ìŠ¤ ì´ì™¸ì— ì—”í‹°í‹° ì‹œí€€ìŠ¤ì™€ ì„ë² ë”©ì„ ì •ì˜
- ë‹¨ì–´ì™€ ì—”í‹°í‹°ì˜ ëª¨ë“  ì‹œí€€ìŠ¤ ìŒì— ë”°ë¼ ë³„ë„ì˜ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ë‘ê³  ì…€í”„ ì–´í…ì…˜ì„ ìˆ˜í–‰
  CINO
- chinese å¤– 6ê°œ minority languagesì— ëŒ€í•œ xlm RoBERTa model |

## 3.4. Hyperparameter Tuning (ì´ì¤€ì„ )

### WandB - Sweepì„ ì‚¬ìš©í•œ Hyperparameter Tuning

![ê·¸ë¦¼ 3.18 klue/roberta-large ëª¨ë¸ì„ sweepì„ ì‚¬ìš©í•´ í•™ìŠµí•œ ê²°ê³¼](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/18.png)

ê·¸ë¦¼ 3.18 klue/roberta-large ëª¨ë¸ì„ sweepì„ ì‚¬ìš©í•´ í•™ìŠµí•œ ê²°ê³¼

### Tuning Configuration

- **Learning Rate**
- **Max Epoch**
- **Batch Size**

- **Weight Decay**
- **LR Scheduler**
- **Warmup Steps**

- **Typed-Entity Marker**
- **Augmentation**

## 3.5. Ensemble (ì´ì¤€ì„ )

### 3.5.1. Soft-Voting

```python
dfs = [pd.read_csv(path) for path in model_paths]

probs = []
for row in zip(*[df['probs'].tolist() for df in dfs])
		temp = []
		for col in zip(*[eval(p) for p in row]):
				temp.append(sum(col) / len(col))
		probs.append(temp)

pred_label = [n2l[i.index(max(i))] ofri in probs]
```

- ê° ëª¨ë¸ì˜ test data ì˜ˆì¸¡ csv ìˆ˜ì§‘
- `probs`: ê° ëª¨ë¸ì˜ classë³„ ì˜ˆì¸¡ í™•ë¥ ì„ ì‚°ìˆ  í‰ê· 
- `pred_label`: í‰ê· ë‚¸ í™•ë¥  ì¤‘ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ class ì„ íƒ

---

# 4. ìˆ˜í–‰ ê²°ê³¼

## 4.1. Single Models (ì´ì¤€ì„ )

![ê·¸ë¦¼ 4.1 ë‹¨ì¼ ëª¨ë¸ì— ëŒ€í•œ ì„±ëŠ¥í‘œ](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/19.png)

ê·¸ë¦¼ 4.1 ë‹¨ì¼ ëª¨ë¸ì— ëŒ€í•œ ì„±ëŠ¥í‘œ

## 4.2. Ensemble Models (ì •ìœ¤ì„)

![ê·¸ë¦¼ 4.2 ì•™ìƒë¸” ì¡°í•© ì„±ëŠ¥í‘œ](%5BKLUE%5D%20Wrap-Up%20Report%207e063543d6154e02ad26f350bcabe04b/20.png)

ê·¸ë¦¼ 4.2 ì•™ìƒë¸” ì¡°í•© ì„±ëŠ¥í‘œ

---

# 5. ìì²´ í‰ê°€

## 5.1. Whatâ€™s Good

- Level 2 ì²« í”„ë¡œì íŠ¸ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  íŒ€ì—ì„œ ê³„íší•œ í”„ë¡œì„¸ìŠ¤ ê·¸ëŒ€ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆì—ˆë‹¤. ëª¨ë“  íŒ€ì›ë“¤ì´ í”„ë¡œì„¸ìŠ¤ ì „ì²´ì— ìµìˆ™í•˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ ê°ì ë§¡ì€ ì—­í• ì„ ì¶©ì‹¤íˆ ì´í–‰í•˜ë©´ì„œ ì§„í–‰ì´ ë”ëŒì§„ë‹¤ê±°ë‚˜ ë©ˆì¶”ëŠ” ì¼ ì—†ì´ ì§„í–‰ë˜ì—ˆë‹¤.
- ëŒ€ë¶€ë¶„ì˜ íŒ€ì›ì´ ê¹ƒí—™ì˜ ë¸Œëœì¹˜ë¥¼ ì´ìš©í•˜ì—¬ í˜‘ì—…í•˜ëŠ” ê²½í—˜ì´ ì ì–´, ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„  merge ê°™ì€ ê²ƒì—ì„œ í”„ë¡œì íŠ¸ íŒŒì¼ì´ ì˜í–¥ì´ ê°€ë”ë¼ë„ ê¹ƒí—™ íˆ´ì— ìµìˆ™í•´ì§€ê¸° ìœ„í•œ ê²½í—˜ìœ¼ë¡œ ìƒê°í•˜ê¸°ë¡œ ë…¼ì˜í•˜ì˜€ê¸°ì— ëª¨ë“  íŒ€ì›ë“¤ì´ ë¶€ë‹´ì—†ì´ ê¹ƒí—™ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì—ˆê³  ì´ëŠ” ê·€ì¤‘í•œ í˜‘ì—… ê²½í—˜ì´ ë˜ì—ˆë‹¤.

## 5.2. Whatâ€™s Bad

- í˜‘ì—…ì„ í•  ë•Œ ê¹ƒí—™ì„ ì‚¬ìš©í•˜ì˜€ì§€ë§Œ í™•ì‹¤í•œ ê¸°ì¤€ì„ ê°€ì§€ê³  commitì´ë‚˜ branch ë§Œë“œëŠ” ê²ƒì´ ì•„ë‹Œ ê°œì¸ ë³„ë¡œ ì‘ì„±í•˜ì˜€ë‹¤. ì´ë²ˆ í”„ë¡œì íŠ¸ ê°™ì´ ì‘ì€ í”„ë¡œì íŠ¸ì—ì„  ìƒê´€ ì—†ì§€ë§Œ í° í”„ë¡œì íŠ¸ë¼ë©´ ë¬¸ì œê°€ ìƒê¸¸ë§Œí•œ ë¶€ë¶„ì´ì—ˆë‹¤. í° í”„ë¡œì íŠ¸ë¥¼ ëŒ€ë¹„í•˜ì—¬ ë‹¤ìŒ í”„ë¡œì íŠ¸ë¶€í„° ê¹ƒí—™ ì‚¬ìš© ê¸°ì¤€ì„ ë§ˆë ¨í•˜ì—¬ ì´ì— ë§ì¶° ì •ì œëœ í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ë§Œë“¤ê³  ì´ êµ¬ì¡°ì— ë§ì¶° í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•  ê²ƒì´ë‹¤.
- ë§ì€ ëª¨ë¸ë“¤ì€ í•™ìŠµì„ ì„±ê³µì‹œì¼°ì§€ë§Œ ëª‡ëª‡ ëª¨ë¸ë“¤ì—ì„  í•™ìŠµì´ ì‹¤íŒ¨í•  ë•Œê°€ ìˆì—ˆë‹¤. í•™ìŠµì„ ì‹¤íŒ¨í•˜ëŠ” ê±´ ê·¸ëŸ´ ìˆ˜ ìˆë‹¤ ìƒê°í•˜ì§€ë§Œ ì‹¤íŒ¨í•œ ì›ì¸ì´ ì™œ ìƒê²¼ëŠ”ì§€ì— ëŒ€í•œ ë¶„ì„ì´ ì‹¤íŒ¨í•˜ëŠ” ê²ƒì€ ë‹¹ì—°í•œ ì¼ì´ ì•„ë‹ˆë‹¤. ì´í›„ í”„ë¡œì íŠ¸ì— ëŒ€ë¹„í•˜ì—¬ ì§€ì‹ì„ ì¢€ ë” ê°–ì¶°ì„œ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ì„ í™•ì‹¤íˆ í•˜ë„ë¡ í•˜ê² ë‹¤.

## 5.3. Whatâ€™s Learned

- ë¨¼ì € ì•™ìƒë¸” ì¡°í•©ì„ ìœ„í•œ ëª¨ë¸ë“¤ì„ ì°¾ëŠ” ê³¼ì •ì—ì„œ Hugging Faceì˜ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì„ í•™ìŠµí•˜ëŠ” ê²½í—˜ì„ í•  ìˆ˜ ìˆì—ˆë‹¤. ê·¸ëƒ¥ ëª¨ë¸ ë³€ìˆ˜ì˜ ì´ë¦„ë§Œ ë°”ê¾¸ë©´ í•™ìŠµë˜ëŠ” ëª¨ë¸ì´ ìˆëŠ”ê°€ í•œí¸ ë‹¤ì‹œ ì¶”ê°€ ì¡°ì •ì´ í•„ìš”í•œ ëª¨ë¸ë“¤ë„ ìˆì–´ ëª¨ë¸ ì¡°ì‘ì— ìµìˆ™í•´ì§€ëŠ” ê·€ì¤‘í•œ ê²½í—˜ì„ ì–»ì„ ìˆ˜ ìˆì—ˆë‹¤.
- ê¹ƒí—™ì„ ì‚¬ìš©í•˜ëŠ” ê³¼ì •ì—ì„œ ë¬¸ì œ ì—†ì´ íŒŒì¼ì„ mergeí•˜ê±°ë‚˜ push í•  ìˆ˜ ìˆì—ˆì§€ë§Œ ë•Œë•Œë¡œ ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ì´ë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì—ì„œ Git ì— ëŒ€í•œ ê°œë…ì„ ê¹Šì´ ì´í•´í•  ìˆ˜ ìˆì—ˆê³  ì´í›„ ê°™ì€ ë¬¸ì œê°€ ë°œìƒ ì‹œ ì´ì „ì— ë¹„í•´ ë¹ ë¥´ê²Œ í•´ê²°í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê¸¸ë €ë‹¤. ì´ ê°™ì€ ëŠ¥ë ¥ì€ ë‹¤ìŒ í”„ë¡œì íŠ¸ í˜¹ì€ ì´í›„ í•„ë“œì—ì„œ íŒ€ì›ê³¼ì˜ í˜‘ì—…ì„ ë”ìš± ìˆ˜ì›”í•˜ê²Œ í•  ê²ƒì´ë‹¤.

---

# Reference

1. [Chung, H. W., Fevry, T., Tsai, H., Johnson, M., & Ruder, S. (2020). Rethinking embedding coupling in pre-trained language models.Â *arXiv preprint arXiv:2010.12821*.](https://arxiv.org/pdf/2010.12821.pdf)
2. [Wei, J., & Zou, K. (2019). Eda: Easy data augmentation techniques for boosting performance on text classification tasks.Â *arXiv preprint arXiv:1901.11196*.](https://arxiv.org/pdf/1901.11196)
3. [Yamada, I., Asai, A., Shindo, H., Takeda, H., & Matsumoto, Y. (2020). LUKE: Deep contextualized entity representations with entity-aware self-attention.Â *arXiv preprint arXiv:2010.01057*.](https://arxiv.org/pdf/2010.01057)
4. [Yang, Z., Xu, Z., Cui, Y., Wang, B., Lin, M., Wu, D., & Chen, Z. (2022). CINO: A Chinese Minority Pre-trained Language Model.Â *arXiv preprint arXiv:2202.13558*.](https://arxiv.org/pdf/2202.13558)
5. [Zhou, W., & Chen, M. (2021). An improved baseline for sentence-level relation extraction.Â *arXiv preprint arXiv:2102.01373*](https://arxiv.org/pdf/2102.01373.pdf)
6. [Zhong, Z., & Chen, D. (2020). A frustratingly easy approach for entity and relation extraction.Â *arXiv preprint arXiv:2010.12812*.](https://aclanthology.org/2021.naacl-main.5.pdf)

---

# íŒŒì¼ êµ¬ì¡°

```
level2_klue-nlp-09
|-- README.md
|-- best_model
|-- config
|   `-- config.yaml
|-- preprocessing
|-- eda
|   |-- JYS.ipynb
|   |-- KSH.ipynb
|   |-- LDH.ipynb
|   `-- LJS.ipynb
|-- inference.py
|-- load_data.py
|-- prediction
|-- requirements.txt
|-- requirements_pl.txt
|-- results
|-- train.py
|-- pl_train.py
|-- pl_sweep.py
|-- pl_inference.py
|-- .gitgnore
`-- utils.py
```
